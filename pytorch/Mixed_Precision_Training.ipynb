{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train_Minimal & Apex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "#from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"Red\">Import Apex</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning:  apex was installed without --cpp_ext.  Falling back to Python flatten and unflatten.\n",
      "Warning:  apex was installed without --cuda_ext. Fused syncbn kernels will be unavailable.  Python fallbacks will be used instead.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedAdam will be unavailable.\n",
      "Warning:  apex was installed without --cuda_ext.  FusedLayerNorm will be unavailable.\n"
     ]
    }
   ],
   "source": [
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "from apex.fp16_utils import *\n",
    "from apex import amp\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader(CIFAR10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=100,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.vgg11_bn(pretrained=True) \n",
    "model.classifier[0] = nn.Linear(512, 4096)\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, len(classes))\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"Red\">Network to half</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_to_half(model)\n",
    "model = torch.nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = optim.SGD(model.parameters(),\n",
    "#                    lr=0.01,\n",
    "#                    momentum=0.9,\n",
    "#                    weight_decay=5e-4,\n",
    "#                    nesterov=True)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"Red\">FP16 Optimizer</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP16_Optimizer processing param group 0:\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([64, 3, 3, 3])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([64])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([64])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([64])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([128, 64, 3, 3])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([128])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([128])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([128])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([256, 128, 3, 3])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([256])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([256])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([256])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([256, 256, 3, 3])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([256])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([256])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([256])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([512, 256, 3, 3])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([512, 512, 3, 3])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([512, 512, 3, 3])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([512, 512, 3, 3])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.FloatTensor with torch.Size([512])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([4096, 512])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([4096])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([4096, 4096])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([4096])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([10, 4096])\n",
      "FP16_Optimizer received torch.cuda.HalfTensor with torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "optimizer = FP16_Optimizer(optimizer, dynamic_loss_scale=True)\n",
    "#optimizer = FP16_Optimizer(optimizer, static_loss_scale = 128.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train 1 epoch function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    bar = tqdm(total=len(loader), leave=False)\n",
    "    total_loss, total_acc, total_num = 0, 0, 0\n",
    "    for idx, feed in enumerate(loader):\n",
    "        # Prepare data\n",
    "        inputs, labels = feed\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        # Foward\n",
    "        outputs = model(inputs)\n",
    "        # Calcurate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # initialize gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        # Update Params\n",
    "        optimizer.step()\n",
    "        # Update bar\n",
    "        ## Accuracy\n",
    "        pred = outputs.data.max(1, keepdim=True)[1]\n",
    "        acc = pred.eq(labels.data.view_as(pred)).sum()\n",
    "        ## Calcurate Score\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        total_acc += acc.item()\n",
    "        total_num += labels.size(0)\n",
    "        bar.set_description(\"Loss: {:.4f}, Accuracy: {:.2f}\".format(\n",
    "            total_loss / total_num, total_acc / total_num * 100), refresh=True)\n",
    "        bar.update()\n",
    "    bar.close()\n",
    "    return total_loss / total_num, total_acc / total_num * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"Red\">Train 1 epoch function for Apex</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop_apex(model, loader, criterion, optimizer):\n",
    "    amp_handle = amp.init(enabled=True)\n",
    "    model.train()\n",
    "    bar = tqdm(total=len(loader), leave=False)\n",
    "    total_loss, total_acc, total_num = 0, 0, 0\n",
    "    for idx, feed in enumerate(loader):\n",
    "        # Prepare data\n",
    "        inputs, labels = feed\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        inputs, labels = inputs.half(), labels\n",
    "        # Foward\n",
    "        outputs = model(inputs)\n",
    "        # Calcurate Loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # initialize gradient\n",
    "        optimizer.zero_grad()\n",
    "        # Backward\n",
    "        with amp_handle.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            #scaled_loss.backward()\n",
    "            optimizer.backward(scaled_loss)\n",
    "        # Update Params\n",
    "        optimizer.step()\n",
    "        # Update bar\n",
    "        ## Accuracy\n",
    "        pred = outputs.data.max(1, keepdim=True)[1]\n",
    "        acc = pred.eq(labels.data.view_as(pred)).sum()\n",
    "        ## Calcurate Score\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        total_acc += acc.item()\n",
    "        total_num += labels.size(0)\n",
    "        bar.set_description(\"Loss: {:.4f}, Accuracy: {:.2f}\".format(\n",
    "            total_loss / total_num, total_acc / total_num * 100), refresh=True)\n",
    "        bar.update()\n",
    "    bar.close()\n",
    "    return total_loss / total_num, total_acc / total_num * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_loop(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total_acc, total_num = 0, 0, 0\n",
    "    bar = tqdm(test_loader, total=len(test_loader), leave=False)\n",
    "    for i, feed in enumerate(loader):\n",
    "        with torch.no_grad():\n",
    "            # Prepare data\n",
    "            inputs, labels = feed\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "            # Foward\n",
    "            outputs = model(inputs)\n",
    "            # Calcurate Loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Update bar\n",
    "            ## Accuracy\n",
    "            pred = outputs.data.max(1, keepdim=True)[1]\n",
    "            acc = pred.eq(labels.data.view_as(pred)).sum()\n",
    "            ## Calcurate Score\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "            total_acc += acc.item()\n",
    "            total_num += labels.size(0)\n",
    "\n",
    "            bar.set_description(\"Loss: {:.4f}, Accuracy: {:.2f}\".format(\n",
    "                total_loss / total_num, total_acc / total_num * 100), refresh=True)\n",
    "            bar.update()\n",
    "    bar.close()\n",
    "    return total_loss / total_num, total_acc / total_num * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERFLOW! Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 2147483648.0, reducing to 1073741824.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 1073741824.0, reducing to 536870912.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 536870912.0, reducing to 268435456.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 268435456.0, reducing to 134217728.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 134217728.0, reducing to 67108864.0\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 1, Train Loss: 0.8808, Train Accuracy: 70.68, Test Loss: 0.6714, Test Accuracy: 78.27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERFLOW! Skipping step. Attempted loss scale: 67108864.0, reducing to 33554432.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 33554432.0, reducing to 16777216.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 16777216.0, reducing to 8388608.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 8388608.0, reducing to 4194304.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 4194304.0, reducing to 2097152.0\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 2, Train Loss: 0.4899, Train Accuracy: 84.42, Test Loss: 0.5312, Test Accuracy: 83.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERFLOW! Skipping step. Attempted loss scale: 2097152.0, reducing to 1048576.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 1048576.0, reducing to 524288.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 524288.0, reducing to 262144.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 262144.0, reducing to 131072.0\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 3, Train Loss: 0.3451, Train Accuracy: 88.89, Test Loss: 0.5676, Test Accuracy: 82.42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERFLOW! Skipping step. Attempted loss scale: 131072.0, reducing to 65536.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 65536.0, reducing to 32768.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 32768.0, reducing to 16384.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 16384.0, reducing to 8192.0\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 4, Train Loss: 0.2523, Train Accuracy: 92.01, Test Loss: 0.5921, Test Accuracy: 82.78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=500), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERFLOW! Skipping step. Attempted loss scale: 8192.0, reducing to 4096.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 4096.0, reducing to 2048.0\n",
      "OVERFLOW! Skipping step. Attempted loss scale: 2048.0, reducing to 1024.0\n",
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 5, Train Loss: 0.1985, Train Accuracy: 93.75, Test Loss: 0.5183, Test Accuracy: 85.08\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "for e in range(max_epochs):\n",
    "    train_loss, train_acc = train_loop_apex(model, train_loader, criterion, optimizer)\n",
    "    test_loss, test_acc = valid_loop(model, test_loader, criterion)\n",
    "    print('Epoch: {}, Train Loss: {:.4f}, Train Accuracy: {:.2f}, Test Loss: {:.4f}, Test Accuracy: {:.2f}'.format(\n",
    "    e + 1, train_loss, train_acc, test_loss, test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'params/model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
